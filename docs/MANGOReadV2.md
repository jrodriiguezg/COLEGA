# ü•≠ MANGO: The Sysadmin AI Assistant

MANGO es un modelo de Inteligencia Artificial especializado en Administraci√≥n de Sistemas Linux y DevOps. Su objetivo es traducir lenguaje natural (desde peticiones t√©cnicas formales hasta jerga coloquial de "compa√±ero de trabajo") en comandos de Bash ejecutables y precisos.

> "Tu compa√±ero de batalla en la terminal, que entiende lo que necesitas incluso a las 3 de la ma√±ana."

## üöÄ Novedades de la Versi√≥n 2.0

### üß† Nueva Arquitectura: CodeT5

Hemos migrado del enfoque Decoder-only (tipo GPT/Qwen) a una arquitectura Encoder-Decoder basada en T5.

* **¬øPor qu√©?** T5 trata la generaci√≥n de c√≥digo como un problema de "traducci√≥n" (Espa√±ol ‚Üí Bash), lo que elimina la "verborrea" innecesaria y garantiza una sintaxis mucho m√°s estricta y segura.
* **Resultado:** Un modelo m√°s ligero, r√°pido y con una tasa de acierto sint√°ctico superior.

### üìö Dataset "Gold Standard" & "Bro-Slang"

El modelo ha sido entrenado con un dataset h√≠brido de +2.600 instrucciones curadas manualmente (MANGO_DATA), dividido en dos vertientes:

* **Core T√©cnico:** Basado en documentaci√≥n oficial, apuntes acad√©micos de administraci√≥n de sistemas y ejercicios de certificaci√≥n (LVM, RAID, Redes, Systemd).
* **Modo "Bro":** Miles de variaciones con jerga real de oficina ("tumba el servicio", "cep√≠llate los logs", "levanta el chiringuito").

## üõ†Ô∏è Instalaci√≥n y Uso

### Requisitos

* Python 3.8+
* PyTorch
* Transformers (Hugging Face)

**Inferencia R√°pida (Python)**
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Cargar el modelo MANGO
```python
model_name = "tusuario/mango-sysadmin-t5"  # (Sustituir por tu repo real)
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

def ask_mango(prompt):
    input_ids = tokenizer.encode(prompt, return_tensors="pt")
    outputs = model.generate(input_ids, max_length=128)
    print(f"ü•≠ Mango dice: {tokenizer.decode(outputs[0], skip_special_tokens=True)}")

# Ejemplos:
ask_mango("B√∫scame los archivos m√°s grandes del disco")
ask_mango("Tumba la interfaz de red eth0")
ask_mango("Cep√≠llate los logs viejos de docker")
``` 
## üìä Capacidades del Modelo

MANGO es capaz de generar one-liners complejos para:

| Categor√≠a | Ejemplos de lo que puede hacer |
| --- | --- |
| Sistemas | systemctl, journalctl, gesti√≥n de procesos (kill, htop). |
| Redes | Diagn√≥stico (ping, dig, traceroute), Firewall (ufw, iptables), Configuraci√≥n IP. |
| DevOps | Docker (ciclo de vida completo), Git (flujo de trabajo), Kubernetes b√°sico. |
| Ficheros | B√∫squedas complejas (find, grep), permisos, compresi√≥n, manipulaci√≥n de texto (awk, sed). |
| Seguridad | Gesti√≥n de claves SSH, GPG, OpenSSL, auditor√≠a b√°sica. |

## üìÇ Estructura del Dataset de Entrenamiento

El conocimiento de MANGO reside en dos ficheros JSONL principales:

* **gold_commands.jsonl:** 1.400+ Comandos t√©cnicos, acad√©micos y legacy.
* **bro_commands.jsonl:** 1.200+ Variaciones coloquiales, jerga y situaciones de estr√©s.


