# ðŸ§ª Funciones Experimentales y Roadmap Futuro

Este documento recopila ideas, propuestas y funcionalidades experimentales planificadas para futuras versiones de **NeoCore (COLEGA)**. Estas caracterÃ­sticas estÃ¡n en fase de investigaciÃ³n y pueden ser inestables o requerir hardware especÃ­fico.

---

## ðŸ”® 1. ClonaciÃ³n de Voz y TTS Personalizado
**Estado:** ðŸ“ Propuesta
**Objetivo:** Permitir que Neo hable con voces personalizadas o clonadas en local, sin depender de modelos pre-entrenados genÃ©ricos.
**ImplementaciÃ³n Potencial:**
*   Integrar **Coqui TTS** o **Tortoise TTS** para generaciÃ³n offline de alta calidad.
*   Crear un script de "grabaciÃ³n de muestras" donde el usuario lee frases para entrenar un *embed* de su propia voz.
*   **DesafÃ­o:** La inferencia en tiempo real de modelos de clonaciÃ³n requiere mucha CPU/GPU.

## ðŸ“¡ 2. Audio Multi-HabitaciÃ³n (SincronizaciÃ³n)
**Estado:** ðŸ“ Propuesta
**Objetivo:** Reproducir mÃºsica o TTS perfectamente sincronizado en mÃºltiples dispositivos "Micro Neo Brain" (ESP32 o Pi Zero) distribuidos por la casa.
**ImplementaciÃ³n Potencial:**
*   Implementar un servidor **Snapcast** en el nÃºcleo.
*   Configurar los satÃ©lites como clientes Snapcast.
*   Permitir "Follow Me" audio: la mÃºsica te sigue de habitaciÃ³n en habitaciÃ³n usando detecciÃ³n de presencia (Bluetooth/VisiÃ³n).

## ðŸ§  3. Aprendizaje Continuo (Fine-tuning Local)
**Estado:** ðŸš§ En InvestigaciÃ³n
**Objetivo:** Que el LLM (Llama/Gemma) aprenda el estilo de hablar y los datos especÃ­ficos del usuario no solo mediante RAG, sino re-entrenando capas del modelo (LoRA).
**ImplementaciÃ³n Potencial:**
*   Pipeline nocturno que toma las interacciones del dÃ­a (ya guardadas en `database.py`).
*   Usar `llama.cpp` o `Unsloth` para ajustar un adaptador LoRA ligero.
*   **Beneficio:** El asistente se vuelve verdaderamente Ãºnico para cada usuario.

## ðŸ‘ï¸ 4. Gestos Visuales "Sin Contacto"
**Estado:** ðŸ“ Propuesta
**Objetivo:** Controlar funciones bÃ¡sicas (parar alarma, siguiente canciÃ³n) mediante gestos con la mano frente a la cÃ¡mara, sin usar la voz.
**ImplementaciÃ³n Potencial:**
*   Usar **MediaPipe Hands** sobre el stream de la cÃ¡mara actual.
*   Detectar gestos simples: "Palma abierta" (Stop), "Pulgar arriba" (Confirmar), "Deslizar" (Siguiente).
*   Ãštil para cuando hay mucho ruido ambiente o es de noche.

## ðŸ” 5. AutenticaciÃ³n BiomÃ©trica Multinodal
**Estado:** ðŸ“ Propuesta
**Objetivo:** Capa de seguridad estricta para comandos sensibles (ej: "Abrir puerta", "Apagar servidor").
**ImplementaciÃ³n Potencial:**
*   Requerir **dos factores simultÃ¡neos**: Reconocimiento Facial + Huella de Voz.
*   Si la cÃ¡mara no ve al usuario autorizado, se deniega el comando aunque la voz coincida (anti-spoofing).

## ðŸŽ­ 6. Inteligencia Emocional Adaptativa
**Estado:** ðŸ“ Propuesta
**Objetivo:** Que Neo detecte el estado de Ã¡nimo tu voz y adapte su respuesta (tono, brevedad).
**ImplementaciÃ³n Potencial:**
*   Analizar prosodia (tono, velocidad) del audio de entrada.
*   Si el usuario suena estresado/urgente -> Respuestas cortas y directas ("Hecho.").
*   Si el usuario suena relajado -> Respuestas mÃ¡s conversacionales y detalladas.

## ðŸ  7. Hub DomÃ³tico Offline (Matter/Zigbee)
**Estado:** ðŸ“ Propuesta
**Objetivo:** Eliminar dependencia de Home Assistant para funciones bÃ¡sicas.
**ImplementaciÃ³n Potencial:**
*   Integrar soporte directo para dongles Zigbee (CC2531).
*   Implementar servidor **Matter** local usando librerÃ­as de Python.
*   Control directo de bombillas y enchufes con latencia cero.

---

> *Â¿Tienes una idea? AÃ±Ã¡dela a esta lista haciendo un Pull Request o editando este archivo.*
